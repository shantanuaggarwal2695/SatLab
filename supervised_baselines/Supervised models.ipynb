{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffa33851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beee5ba5",
   "metadata": {},
   "source": [
    "# Try with Multiple Supervised models for image classification\n",
    "\n",
    "1. Random forest\n",
    "2. CNN\n",
    "3. DeepSAT\n",
    "4. DeepSAT-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf97a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 17)\n"
     ]
    }
   ],
   "source": [
    "train =  pd.read_csv(\"../data/experiments/validation/set_5/train.csv\", index_col=False, header=0)\n",
    "test = pd.read_csv(\"../data/experiments/validation/set_5/test.csv\", index_col=False, header=0)\n",
    "cols= [\"glcm_contrast_Scaled\", \"glcm_dissimilarity_Scaled\", \"glcm_homogeneity_Scaled\", \"glcm_energy_Scaled\", \"glcm_correlation_Scaled\", \"glcm_ASM_Scaled\", \"healthcare\", \"shopping_malls\", \"schools\", \"waste\", \"roads\", \"forest\", \"residential\",\"powerstation\", \"leisure\", \"meadows\", \"Class_x\"]\n",
    "train = train.iloc[:20000, :]\n",
    "train = train[cols]\n",
    "test = test[cols]\n",
    "\n",
    "print(test.shape)\n",
    "def convert(x):\n",
    "    if x == -1:\n",
    "        return 1\n",
    "    else:\n",
    "        return x\n",
    "train['Class'] = train['Class_x'].apply(convert)\n",
    "test['Class'] = test['Class_x'].apply(convert)\n",
    "\n",
    "train = train.drop(['Class_x'], axis=1)\n",
    "test = test.drop(['Class_x'], axis=1)\n",
    "\n",
    "# geo_df = combined_df[[\"origin\",\"healthcare\", \"shopping_malls\", \"schools\", \"waste\", \"roads\" ,\"forest\", \"residential\", \"powerstation\", \"leisure\", \"meadows\", \"Class\"]]\n",
    "# textural_df = combined_df[[\"origin\", \"glcm_contrast_Scaled\", \"glcm_dissimilarity_Scaled\", \"glcm_homogeneity_Scaled\", \"glcm_energy_Scaled\", \"glcm_correlation_Scaled\",  \"glcm_ASM_Scaled\", \"Class\"]]\n",
    "\n",
    "# combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4338f37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glcm_contrast_Scaled</th>\n",
       "      <th>glcm_dissimilarity_Scaled</th>\n",
       "      <th>glcm_homogeneity_Scaled</th>\n",
       "      <th>glcm_energy_Scaled</th>\n",
       "      <th>glcm_correlation_Scaled</th>\n",
       "      <th>glcm_ASM_Scaled</th>\n",
       "      <th>healthcare</th>\n",
       "      <th>shopping_malls</th>\n",
       "      <th>schools</th>\n",
       "      <th>waste</th>\n",
       "      <th>roads</th>\n",
       "      <th>forest</th>\n",
       "      <th>residential</th>\n",
       "      <th>powerstation</th>\n",
       "      <th>leisure</th>\n",
       "      <th>meadows</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.345</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.345</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.345</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.345</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.345</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   glcm_contrast_Scaled  glcm_dissimilarity_Scaled  glcm_homogeneity_Scaled  \\\n",
       "0                 0.345                        0.4                    0.582   \n",
       "1                 0.345                        0.4                    0.582   \n",
       "2                 0.345                        0.4                    0.582   \n",
       "3                 0.345                        0.4                    0.582   \n",
       "4                 0.345                        0.4                    0.582   \n",
       "\n",
       "   glcm_energy_Scaled  glcm_correlation_Scaled  glcm_ASM_Scaled  healthcare  \\\n",
       "0               0.001                    0.199            0.001        0.22   \n",
       "1               0.001                    0.199            0.001        0.22   \n",
       "2               0.001                    0.199            0.001        0.22   \n",
       "3               0.001                    0.199            0.001        0.22   \n",
       "4               0.001                    0.199            0.001        0.22   \n",
       "\n",
       "   shopping_malls  schools  waste  roads  forest  residential  powerstation  \\\n",
       "0            0.23     0.24   0.56   0.08    0.64         0.24          0.04   \n",
       "1            0.23     0.24   0.56   0.08    0.64         0.24          0.04   \n",
       "2            0.23     0.24   0.56   0.08    0.64         0.24          0.04   \n",
       "3            0.23     0.24   0.56   0.08    0.64         0.24          0.04   \n",
       "4            0.23     0.24   0.56   0.08    0.64         0.24          0.04   \n",
       "\n",
       "   leisure  meadows  Class  \n",
       "0     0.11     0.27      1  \n",
       "1     0.11     0.27      1  \n",
       "2     0.11     0.27      1  \n",
       "3     0.11     0.27      1  \n",
       "4     0.11     0.27      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2f09d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>Class</th>\n",
       "      <th>glcm_contrast_Scaled</th>\n",
       "      <th>glcm_dissimilarity_Scaled</th>\n",
       "      <th>glcm_homogeneity_Scaled</th>\n",
       "      <th>glcm_energy_Scaled</th>\n",
       "      <th>glcm_correlation_Scaled</th>\n",
       "      <th>glcm_ASM_Scaled</th>\n",
       "      <th>healthcare</th>\n",
       "      <th>shopping_malls</th>\n",
       "      <th>schools</th>\n",
       "      <th>waste</th>\n",
       "      <th>roads</th>\n",
       "      <th>forest</th>\n",
       "      <th>residential</th>\n",
       "      <th>powerstation</th>\n",
       "      <th>leisure</th>\n",
       "      <th>meadows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin  Class  glcm_contrast_Scaled  glcm_dissimilarity_Scaled  \\\n",
       "0  image0      1                 0.345                        0.4   \n",
       "1  image0      1                 0.345                        0.4   \n",
       "2  image0      1                 0.345                        0.4   \n",
       "3  image0      1                 0.345                        0.4   \n",
       "4  image0      1                 0.345                        0.4   \n",
       "\n",
       "   glcm_homogeneity_Scaled  glcm_energy_Scaled  glcm_correlation_Scaled  \\\n",
       "0                    0.582               0.001                    0.199   \n",
       "1                    0.582               0.001                    0.199   \n",
       "2                    0.582               0.001                    0.199   \n",
       "3                    0.582               0.001                    0.199   \n",
       "4                    0.582               0.001                    0.199   \n",
       "\n",
       "   glcm_ASM_Scaled  healthcare  shopping_malls  schools  waste  roads  forest  \\\n",
       "0            0.001        0.22            0.23     0.24   0.56   0.08    0.64   \n",
       "1            0.001        0.22            0.23     0.24   0.56   0.08    0.64   \n",
       "2            0.001        0.22            0.23     0.24   0.56   0.08    0.64   \n",
       "3            0.001        0.22            0.23     0.24   0.56   0.08    0.64   \n",
       "4            0.001        0.22            0.23     0.24   0.56   0.08    0.64   \n",
       "\n",
       "   residential  powerstation  leisure  meadows  \n",
       "0         0.24          0.04     0.11     0.27  \n",
       "1         0.24          0.04     0.11     0.27  \n",
       "2         0.24          0.04     0.11     0.27  \n",
       "3         0.24          0.04     0.11     0.27  \n",
       "4         0.24          0.04     0.11     0.27  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =  pd.read_csv(\"../data/experiments/features/synthetic_data/data_40000.csv\", index_col=False, header=None, names=[\"origin\", \"Class\", \"glcm_contrast_Scaled\", \"glcm_dissimilarity_Scaled\", \"glcm_homogeneity_Scaled\", \"glcm_energy_Scaled\", \"glcm_correlation_Scaled\",  \"glcm_ASM_Scaled\", \"healthcare\", \"shopping_malls\", \"schools\", \"waste\", \"roads\" ,\"forest\", \"residential\", \"powerstation\", \"leisure\", \"meadows\"])\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3745b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols= [\"glcm_contrast_Scaled\", \"glcm_dissimilarity_Scaled\", \"glcm_homogeneity_Scaled\", \"glcm_energy_Scaled\", \"glcm_correlation_Scaled\", \"glcm_ASM_Scaled\", \"healthcare\", \"shopping_malls\", \"schools\", \"waste\", \"roads\", \"forest\", \"residential\",\"powerstation\", \"leisure\", \"meadows\", \"Class\"]\n",
    "# data = combined_df[cols]\n",
    "# data = data[(data['Class']==1) | (data['Class']==0)]\n",
    "\n",
    "train_x = train[[\"glcm_contrast_Scaled\", \"glcm_dissimilarity_Scaled\", \"glcm_homogeneity_Scaled\", \"glcm_energy_Scaled\", \"glcm_correlation_Scaled\", \"glcm_ASM_Scaled\", \"healthcare\", \"shopping_malls\", \"schools\", \"waste\", \"roads\", \"forest\", \"residential\",\"powerstation\", \"leisure\", \"meadows\"]]\n",
    "train_y = train[['Class']]\n",
    "\n",
    "test_x = test[[\"glcm_contrast_Scaled\", \"glcm_dissimilarity_Scaled\", \"glcm_homogeneity_Scaled\", \"glcm_energy_Scaled\", \"glcm_correlation_Scaled\", \"glcm_ASM_Scaled\", \"healthcare\", \"shopping_malls\", \"schools\", \"waste\", \"roads\", \"forest\", \"residential\",\"powerstation\", \"leisure\", \"meadows\"]]\n",
    "test_y = test[['Class']]\n",
    "\n",
    "# train_feat = train_x.iloc[:70000, :]\n",
    "# train_label = train_y.iloc[:70000, :]\n",
    "\n",
    "# test_feat = train_x.iloc[70001:, :]\n",
    "# test_label = train_y.iloc[70001:, :]\n",
    "\n",
    "\n",
    "\n",
    "# print(train_feat.head())\n",
    "# print(test_feat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07455129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "512468be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5383546352386475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import time \n",
    "\n",
    "t1 = time.time()\n",
    "clf = RandomForestClassifier(max_depth=5, random_state=0)\n",
    "model = clf.fit(np.array(train_x), train_y['Class'])\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2-t1)\n",
    "\n",
    "prediction = model.predict(np.array(test_x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "e5069748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6785714285714286 0.8636363636363636\n",
      "0.76\n"
     ]
    }
   ],
   "source": [
    "def true_positive(actual, predicted):\n",
    "    count = 0\n",
    "    for (i, label) in enumerate(actual):\n",
    "        if actual[i]==1 and predicted[i]==1:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "def true_negative(actual, predicted):\n",
    "    count = 0\n",
    "    for (i, label) in enumerate(actual):\n",
    "        if actual[i]==0 and predicted[i]==0:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "def false_positive(actual, predicted):\n",
    "    count = 0\n",
    "    for (i, label) in enumerate(actual):\n",
    "        if actual[i]==0 and predicted[i]==1:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "def false_negative(actual, predicted):\n",
    "    count = 0\n",
    "    for (i, label) in enumerate(actual):\n",
    "        if actual[i]==1 and predicted[i]==0:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "actual = test_y['Class'].to_list()\n",
    "predict = prediction.tolist()\n",
    "\n",
    "precision = true_positive(actual, predict)/(true_positive(actual, predict)+false_positive(actual, predict))\n",
    "recall = true_positive(actual, predict)/(true_positive(actual, predict) + false_negative(actual, predict))\n",
    "\n",
    "print(precision, recall)\n",
    "\n",
    "print(2*(precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57af585",
   "metadata": {},
   "source": [
    "# Convolutional Neural Netwrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83c99e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train =  pd.read_csv(\"../data/experiments/validation/set_5/train.csv\", index_col=False, header=0)\n",
    "test = pd.read_csv(\"../data/experiments/validation/set_5/test.csv\", index_col=False, header=0)\n",
    "cols= [\"origin\",\"glcm_contrast_Scaled\", \"glcm_dissimilarity_Scaled\", \"glcm_homogeneity_Scaled\", \"glcm_energy_Scaled\", \"glcm_correlation_Scaled\", \"glcm_ASM_Scaled\", \"healthcare\", \"shopping_malls\", \"schools\", \"waste\", \"roads\", \"forest\", \"residential\",\"powerstation\", \"leisure\", \"meadows\", \"Class_x\"]\n",
    "train = train.iloc[:80000, :]\n",
    "train = train[cols]\n",
    "test = test[cols]\n",
    "\n",
    "train['Class'] = train['Class_x'].apply(convert)\n",
    "test['Class'] = test['Class_x'].apply(convert)\n",
    "\n",
    "train = train.drop(['Class_x'], axis=1)\n",
    "test = test.drop(['Class_x'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "745a22ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "def getBands(rasterImage):\n",
    "    \n",
    "    with rasterio.open(rasterImage) as dataset:\n",
    "        band0 = dataset.read(1)\n",
    "        band1 = dataset.read(2)\n",
    "        band2 = dataset.read(3)\n",
    "        \n",
    "        max_0 = np.amax(band0)\n",
    "        band0 = band0/(max_0/255.0)\n",
    "        max_1 = np.amax(band1)\n",
    "        band1 = band1/(max_1/255.0)\n",
    "        max_2 = np.amax(band2)\n",
    "        band2 = band2/(band2/255.0)\n",
    "        return np.dstack((band0, band1, band2))\n",
    "#         return np.ravel(dataset.read(band)).tolist()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff358755",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train['Class']\n",
    "test_label = test['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904f4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1d6fb89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168.44963383674622\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "# conv_data = combined_df[(combined_df['Class']==1) | (combined_df['Class']==0)]\n",
    "train_images = train['origin']\n",
    "test_images = test['origin']\n",
    "\n",
    "train = train_images.to_list()\n",
    "test = test_images.to_list()\n",
    "\n",
    "train_dir = \"../data/manual_audit/\"\n",
    "\n",
    "t1 = time.time()\n",
    "train_feat = []\n",
    "for (i,images) in enumerate(train_images):\n",
    "    train_feat.append(getBands(train_dir+images+\".tif\"))\n",
    "\n",
    "train_feat = np.array(train_feat)\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2-t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "278c0a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 32, 32, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Prepare test data '''\n",
    "\n",
    "test_feat = []\n",
    "for (i,images) in enumerate(test_images):\n",
    "    test_feat.append(getBands(train_dir+images+\".tif\"))\n",
    "\n",
    "test_feat = np.array(test_feat)\n",
    "test_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7006ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Libararies '''\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU, ReLU, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14d8eb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5000/5000 [==============================] - 52s 10ms/step - loss: 0.0312 - accuracy: 0.9822 - val_loss: 2.7680 - val_accuracy: 0.6000\n",
      "Epoch 2/20\n",
      "5000/5000 [==============================] - 51s 10ms/step - loss: 5.1846e-07 - accuracy: 1.0000 - val_loss: 3.2761 - val_accuracy: 0.6000\n",
      "Epoch 00002: early stopping\n",
      "104.07019257545471\n"
     ]
    }
   ],
   "source": [
    "''' Prepare Model '''\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "nClasses = 2\n",
    "train_X = train_feat.reshape(-1, 32,32, 3)\n",
    "test_X = test_feat.reshape(-1, 32,32, 3)\n",
    "# train_X.shape, test_X.shape\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255.\n",
    "\n",
    "train_Y_one_hot = to_categorical(train_label)\n",
    "test_Y_one_hot = to_categorical(test_label)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = 2\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "fashion_model = Sequential()\n",
    "fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(32,32,3),padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(128, activation='linear'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "t1 = time.time()\n",
    "\n",
    "fashion_train = fashion_model.fit(train_X, train_Y_one_hot, batch_size=batch_size,epochs=epochs,verbose=1, validation_data=(test_X, test_Y_one_hot), callbacks=[es])\n",
    "\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "695fb136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6785714285714286 0.8636363636363636\n",
      "0.76\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(fashion_model.predict(test_X), axis=1)\n",
    "actual = test_label\n",
    "predict = prediction.tolist()\n",
    "\n",
    "precision = true_positive(actual, predict)/(true_positive(actual, predict)+false_positive(actual, predict))\n",
    "recall = true_positive(actual, predict)/(true_positive(actual, predict) + false_negative(actual, predict))\n",
    "\n",
    "print(precision, recall)\n",
    "\n",
    "print(2*(precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e1560a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4374fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = fashion_model.input                                           \n",
    "outputs = [layer.output for layer in fashion_model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46603362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d\n",
      "leaky_re_lu\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "leaky_re_lu_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "leaky_re_lu_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "dense\n",
      "leaky_re_lu_3\n",
      "dense_1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No such layer: leaky_re_lu_119. Existing layers are [<keras.layers.convolutional.Conv2D object at 0x7f9d91bbed10>, <keras.layers.advanced_activations.LeakyReLU object at 0x7f9d0a122ad0>, <keras.layers.pooling.MaxPooling2D object at 0x7f9cc47d6850>, <keras.layers.convolutional.Conv2D object at 0x7f9cc47d6bd0>, <keras.layers.advanced_activations.LeakyReLU object at 0x7f9cc47d67d0>, <keras.layers.pooling.MaxPooling2D object at 0x7f9cc4759f50>, <keras.layers.convolutional.Conv2D object at 0x7f9cc47b1b90>, <keras.layers.advanced_activations.LeakyReLU object at 0x7f9cc47688d0>, <keras.layers.pooling.MaxPooling2D object at 0x7f9cc47681d0>, <keras.layers.core.flatten.Flatten object at 0x7f9cc46fb410>, <keras.layers.core.dense.Dense object at 0x7f9cc4768fd0>, <keras.layers.advanced_activations.LeakyReLU object at 0x7f9cc47b1590>, <keras.layers.core.dense.Dense object at 0x7f9cc4708690>].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25713/586705979.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'leaky_re_lu_119'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mintermediate_layer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfashion_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfashion_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintermediate_layer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/knowledgebase-ezGPqgFo/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   2629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2631\u001b[0;31m       raise ValueError(f'No such layer: {name}. Existing layers are '\n\u001b[0m\u001b[1;32m   2632\u001b[0m                        f'{self.layers}.')\n\u001b[1;32m   2633\u001b[0m     raise ValueError('Provide either a layer name or layer index at '\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: leaky_re_lu_119. Existing layers are [<keras.layers.convolutional.Conv2D object at 0x7f9d91bbed10>, <keras.layers.advanced_activations.LeakyReLU object at 0x7f9d0a122ad0>, <keras.layers.pooling.MaxPooling2D object at 0x7f9cc47d6850>, <keras.layers.convolutional.Conv2D object at 0x7f9cc47d6bd0>, <keras.layers.advanced_activations.LeakyReLU object at 0x7f9cc47d67d0>, <keras.layers.pooling.MaxPooling2D object at 0x7f9cc4759f50>, <keras.layers.convolutional.Conv2D object at 0x7f9cc47b1b90>, <keras.layers.advanced_activations.LeakyReLU object at 0x7f9cc47688d0>, <keras.layers.pooling.MaxPooling2D object at 0x7f9cc47681d0>, <keras.layers.core.flatten.Flatten object at 0x7f9cc46fb410>, <keras.layers.core.dense.Dense object at 0x7f9cc4768fd0>, <keras.layers.advanced_activations.LeakyReLU object at 0x7f9cc47b1590>, <keras.layers.core.dense.Dense object at 0x7f9cc4708690>]."
     ]
    }
   ],
   "source": [
    "for layer in fashion_model.layers:\n",
    "    print(layer.name)\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "layer_name = 'leaky_re_lu_119'\n",
    "intermediate_layer_model = keras.Model(inputs=fashion_model.input,outputs=fashion_model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "f6b81abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 128)"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_feat = intermediate_output.numpy()\n",
    "cnn_feat\n",
    "\n",
    "cnn_feat_test = intermediate_layer_model(test_X).numpy()\n",
    "cnn_feat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "ea947990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 156)"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tex_feat = combined_df[(combined_df[\"Class\"]==0) | (combined_df['Class']==1)][[\"glcm_contrast_Scaled\", \"glcm_dissimilarity_Scaled\", \"glcm_homogeneity_Scaled\", \"glcm_energy_Scaled\", \"glcm_correlation_Scaled\",  \"glcm_ASM_Scaled\"]]\n",
    "# train_feat = tex_feat.iloc[:70000, :]\n",
    "# test_feat = tex_feat.iloc[70001:, :]\n",
    "\n",
    "train =  pd.read_csv(\"../data/experiments/validation/set_5/train.csv\", index_col=False, header=0)\n",
    "test = pd.read_csv(\"../data/experiments/validation/set_5/test.csv\", index_col=False, header=0)\n",
    "cols= [\"glcm_contrast_Scaled\", \"glcm_dissimilarity_Scaled\", \"glcm_homogeneity_Scaled\", \"glcm_energy_Scaled\", \"glcm_correlation_Scaled\", \"glcm_ASM_Scaled\"]\n",
    "\n",
    "train_X = train[cols].iloc[:40000, :]\n",
    "test_X = test[cols] \n",
    "\n",
    "# train_X.shape\n",
    "train_feat_new = np.repeat(np.array(train_X), 26, axis=1)\n",
    "train_feat_new.shape\n",
    "test_feat_new = np.repeat(np.array(test_X), 26, axis=1)\n",
    "test_feat_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "744d6125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 284)"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features_train = np.hstack((cnn_feat, train_feat_new))\n",
    "final_features_test = np.hstack((cnn_feat_test, test_feat_new))\n",
    "\n",
    "final_features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "39a17367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>Class_x</th>\n",
       "      <th>Geom_x</th>\n",
       "      <th>glcm_contrast_Scaled</th>\n",
       "      <th>glcm_dissimilarity_Scaled</th>\n",
       "      <th>glcm_homogeneity_Scaled</th>\n",
       "      <th>glcm_energy_Scaled</th>\n",
       "      <th>glcm_correlation_Scaled</th>\n",
       "      <th>glcm_ASM_Scaled</th>\n",
       "      <th>healthcare</th>\n",
       "      <th>shopping_malls</th>\n",
       "      <th>schools</th>\n",
       "      <th>waste</th>\n",
       "      <th>roads</th>\n",
       "      <th>forest</th>\n",
       "      <th>residential</th>\n",
       "      <th>powerstation</th>\n",
       "      <th>leisure</th>\n",
       "      <th>meadows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-58.71434927939868, -34.7287397846191]</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-58.71434927939868, -34.7287397846191]</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-58.71434927939868, -34.7287397846191]</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-58.71434927939868, -34.7287397846191]</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-58.71434927939868, -34.7287397846191]</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin  Class_x                                   Geom_x  \\\n",
       "0  image0        1  [-58.71434927939868, -34.7287397846191]   \n",
       "1  image0        1  [-58.71434927939868, -34.7287397846191]   \n",
       "2  image0        1  [-58.71434927939868, -34.7287397846191]   \n",
       "3  image0        1  [-58.71434927939868, -34.7287397846191]   \n",
       "4  image0        1  [-58.71434927939868, -34.7287397846191]   \n",
       "\n",
       "   glcm_contrast_Scaled  glcm_dissimilarity_Scaled  glcm_homogeneity_Scaled  \\\n",
       "0                 0.345                        0.4                    0.582   \n",
       "1                 0.345                        0.4                    0.582   \n",
       "2                 0.345                        0.4                    0.582   \n",
       "3                 0.345                        0.4                    0.582   \n",
       "4                 0.345                        0.4                    0.582   \n",
       "\n",
       "   glcm_energy_Scaled  glcm_correlation_Scaled  glcm_ASM_Scaled  healthcare  \\\n",
       "0               0.001                    0.199            0.001        0.22   \n",
       "1               0.001                    0.199            0.001        0.22   \n",
       "2               0.001                    0.199            0.001        0.22   \n",
       "3               0.001                    0.199            0.001        0.22   \n",
       "4               0.001                    0.199            0.001        0.22   \n",
       "\n",
       "   shopping_malls  schools  waste  roads  forest  residential  powerstation  \\\n",
       "0            0.23     0.24   0.56   0.08    0.64         0.24          0.04   \n",
       "1            0.23     0.24   0.56   0.08    0.64         0.24          0.04   \n",
       "2            0.23     0.24   0.56   0.08    0.64         0.24          0.04   \n",
       "3            0.23     0.24   0.56   0.08    0.64         0.24          0.04   \n",
       "4            0.23     0.24   0.56   0.08    0.64         0.24          0.04   \n",
       "\n",
       "   leisure  meadows  \n",
       "0     0.11     0.27  \n",
       "1     0.11     0.27  \n",
       "2     0.11     0.27  \n",
       "3     0.11     0.27  \n",
       "4     0.11     0.27  "
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "10830fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_sat2 = Sequential()\n",
    "deep_sat2.add(Input(shape=(284,)))\n",
    "deep_sat2.add(Dense(32, activation='relu'))\n",
    "deep_sat2.add(BatchNormalization(axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,beta_initializer=\"zeros\",gamma_initializer=\"ones\",moving_mean_initializer=\"zeros\",moving_variance_initializer=\"ones\",beta_regularizer=None,gamma_regularizer=None,beta_constraint=None,gamma_constraint=None))\n",
    "deep_sat2.add(ReLU(max_value=1.0))\n",
    "deep_sat2.add(Dense(128, activation='relu'))\n",
    "deep_sat2.add(ReLU(max_value=1.0))\n",
    "deep_sat2.add(Dropout(0.4))\n",
    "deep_sat2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "deep_sat2.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "deep_sat2.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "22988a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 284)\n",
      "(40000, 284)\n",
      "Epoch 1/20\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 3.6396 - val_accuracy: 0.5750\n",
      "Epoch 2/20\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 2.7012e-04 - accuracy: 0.9999 - val_loss: 4.2365 - val_accuracy: 0.5500\n",
      "Epoch 00002: early stopping\n",
      "17.439040184020996\n"
     ]
    }
   ],
   "source": [
    "print(final_features_test.shape)\n",
    "print(final_features_train.shape)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "num_classes = 2\n",
    "\n",
    "t1 = time.time()\n",
    "model_deep2 = deep_sat2.fit(final_features_train, train_Y_one_hot, batch_size=batch_size,epochs=epochs,verbose=1, validation_data=(final_features_test, test_Y_one_hot), callbacks=[es])\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "14aaa4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.6818181818181818\n",
      "0.6382978723404256\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(deep_sat2.predict(final_features_test), axis=1)\n",
    "actual = test_label\n",
    "predict = predictions.tolist()\n",
    "\n",
    "precision = true_positive(actual, predict)/(true_positive(actual, predict)+false_positive(actual, predict))\n",
    "recall = true_positive(actual, predict)/(true_positive(actual, predict) + false_negative(actual, predict))\n",
    "\n",
    "print(precision, recall)\n",
    "\n",
    "print(2*(precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff067c8",
   "metadata": {},
   "source": [
    "# Snorkel with learning with 80000 data points and testing on 20000 data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "a83e0d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 18)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train =  pd.read_csv(\"../data/experiments/validation/set_5/train.csv\", index_col=False, header=0)\n",
    "test = pd.read_csv(\"../data/experiments/validation/set_5/test.csv\", index_col=False, header=0)\n",
    "cols= [\"origin\",\"glcm_contrast_Scaled\", \"glcm_dissimilarity_Scaled\", \"glcm_homogeneity_Scaled\", \"glcm_energy_Scaled\", \"glcm_correlation_Scaled\", \"glcm_ASM_Scaled\", \"healthcare\", \"shopping_malls\", \"schools\", \"waste\", \"roads\", \"forest\", \"residential\",\"powerstation\", \"leisure\", \"meadows\", \"Class_x\"]\n",
    "\n",
    "train = train[cols]\n",
    "test = test[cols]\n",
    "\n",
    "train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "7e6f694b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 80000/80000 [00:14<00:00, 5507.91it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|                                                | 0/300 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=117.551]\n",
      "INFO:root:[10 epochs]: TRAIN:[loss=41.000]\n",
      "INFO:root:[20 epochs]: TRAIN:[loss=9.858]\n",
      "INFO:root:[30 epochs]: TRAIN:[loss=2.835]\n",
      "INFO:root:[40 epochs]: TRAIN:[loss=3.235]\n",
      "INFO:root:[50 epochs]: TRAIN:[loss=2.469]\n",
      "INFO:root:[60 epochs]: TRAIN:[loss=2.008]\n",
      "INFO:root:[70 epochs]: TRAIN:[loss=1.933]\n",
      "INFO:root:[80 epochs]: TRAIN:[loss=1.929]\n",
      "INFO:root:[90 epochs]: TRAIN:[loss=1.916]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=1.909]\n",
      " 36%|█████████████                       | 109/300 [00:00<00:00, 1085.18epoch/s]INFO:root:[110 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[120 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[130 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[140 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[150 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[160 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[170 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[180 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[190 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[200 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[210 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[220 epochs]: TRAIN:[loss=1.908]\n",
      " 74%|██████████████████████████▌         | 221/300 [00:00<00:00, 1099.62epoch/s]INFO:root:[230 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[240 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[250 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[260 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[270 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[280 epochs]: TRAIN:[loss=1.908]\n",
      "INFO:root:[290 epochs]: TRAIN:[loss=1.908]\n",
      "100%|████████████████████████████████████| 300/300 [00:00<00:00, 1104.14epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3687102794647217\n"
     ]
    }
   ],
   "source": [
    "import snorkel\n",
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "\n",
    "y_train = train.iloc[:,0:18]\n",
    "\n",
    "y_label = train['Class_x']\n",
    "\n",
    "# y_label_new = \n",
    "\n",
    "SLUM = 1\n",
    "NON_SLUM = 0\n",
    "ABSTAIN = -1\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def lf1(x):\n",
    "    if x.glcm_correlation_Scaled <= 0.6509999930858612:\n",
    "        if x.glcm_homogeneity_Scaled <= 0.6689999997615814:\n",
    "            return NON_SLUM\n",
    "        else:  # if glcm_homogeneity_Scaled > 0.6689999997615814\n",
    "            if x.glcm_correlation_Scaled <= 0.4884999990463257:\n",
    "                return NON_SLUM\n",
    "            else:  # if glcm_correlation_Scaled > 0.4884999990463257\n",
    "                return SLUM\n",
    "    else:  # if glcm_correlation_Scaled > 0.6509999930858612\n",
    "        if x.glcm_homogeneity_Scaled <= 0.515500009059906:\n",
    "            return NON_SLUM\n",
    "        else:  # if glcm_homogeneity_Scaled > 0.515500009059906\n",
    "            return SLUM\n",
    "        \n",
    "@labeling_function()\n",
    "def lf2(x):\n",
    "    if x.glcm_energy_Scaled <= 0.5824999958276749:\n",
    "        return NON_SLUM\n",
    "    else:  # if glcm_energy_Scaled > 0.5824999958276749\n",
    "        return SLUM\n",
    "    \n",
    "@labeling_function()\n",
    "def lf3(x):\n",
    "    if x.healthcare <= 0.19999999552965164:\n",
    "        if x.glcm_homogeneity_Scaled <= 0.6480000019073486:\n",
    "            return SLUM\n",
    "        else:  # if glcm_homogeneity_Scaled > 0.6480000019073486\n",
    "            if x.glcm_ASM_Scaled <= 0.49949998955707997:\n",
    "                return NON_SLUM\n",
    "            else:  # if glcm_ASM_Scaled > 0.49949998955707997\n",
    "                return SLUM\n",
    "    else:  # if healthcare > 0.19999999552965164\n",
    "        if x.glcm_homogeneity_Scaled <= 0.8844999969005585:\n",
    "            if x.glcm_contrast_Scaled <= 0.5954999923706055:\n",
    "                return NON_SLUM\n",
    "            else:  # if glcm_contrast_Scaled > 0.5954999923706055\n",
    "                return SLUM\n",
    "        else:  # if glcm_homogeneity_Scaled > 0.88449999690055\n",
    "            return NON_SLUM\n",
    "        \n",
    "@labeling_function()\n",
    "def lf4(x):\n",
    "    if x.glcm_homogeneity_Scaled <= 0.6689999997615814:\n",
    "        return SLUM\n",
    "    else:  # if glcm_homogeneity_Scaled > 0.6689999997615814\n",
    "        if x.glcm_energy_Scaled <= 0.5824999958276749:\n",
    "            return SLUM\n",
    "        else:  # if glcm_energy_Scaled > 0.5824999958276749\n",
    "            return NON_SLUM\n",
    "        \n",
    "\n",
    "@labeling_function()        \n",
    "def lf5(x):\n",
    "    if x.glcm_ASM_Scaled <= 0.6239999830722809:\n",
    "        return SLUM\n",
    "    else:  # if glcm_ASM_Scaled > 0.6239999830722809\n",
    "        return NON_SLUM\n",
    "\n",
    "@labeling_function()\n",
    "def lf6(x):\n",
    "    if x.residential <= 0.4749999940395355:\n",
    "        return NON_SLUM\n",
    "    else:  # if residential > 0.4749999940395355\n",
    "        return SLUM\n",
    "    \n",
    "@labeling_function()\n",
    "def lf7(x):\n",
    "    if x.shopping_malls <= 0.48499999940395355:\n",
    "        return NON_SLUM\n",
    "    else:  # if shopping_malls > 0.48499999940395355\n",
    "        return SLUM\n",
    "    \n",
    "@labeling_function()\n",
    "def lf8(x):\n",
    "    if x.roads <= 0.10999999940395355:\n",
    "        return NON_SLUM\n",
    "    else:  # if roads > 0.10999999940395355\n",
    "        return SLUM  # if leisure > 0.32999999821186066\n",
    "        \n",
    "@labeling_function()\n",
    "def lf9(x):\n",
    "    if x.powerstation <= 0.29500000178813934:\n",
    "        return NON_SLUM\n",
    "    else:  # if powerstation > 0.29500000178813934\n",
    "        return SLUM\n",
    "    \n",
    "@labeling_function()\n",
    "def lf10(x):\n",
    "    if x.shopping_malls <= 0.48499999940395355:\n",
    "        return NON_SLUM\n",
    "    else:  # if shopping_malls > 0.48499999940395355\n",
    "        return SLUM\n",
    "    \n",
    "@labeling_function()    \n",
    "def lf11(x):\n",
    "    if x.residential <= 0.13999999687075615:\n",
    "        if x.glcm_homogeneity_Scaled <= 0.5009999945759773:\n",
    "            return SLUM\n",
    "        else:  # if glcm_homogeneity_Scaled > 0.5009999945759773\n",
    "            return NON_SLUM\n",
    "    else:  # if residential > 0.13999999687075615\n",
    "        return SLUM\n",
    "\n",
    "@labeling_function()\n",
    "def lf12(x):\n",
    "    if x.shopping_malls <= 0.10000000149011612:\n",
    "        if x.glcm_energy_Scaled <= 0.4984999959706329:\n",
    "            return SLUM\n",
    "        else:  # if glcm_energy_Scaled > 0.4984999959706329\n",
    "            return NON_SLUM\n",
    "    else:  # if shopping_malls > 0.10000000149011612\n",
    "        return SLUM\n",
    "    \n",
    "@labeling_function()\n",
    "def lf13(x):\n",
    "    if x.residential <= 0.13999999687075615:\n",
    "        if x.powerstation <= 0.07499999925494194:\n",
    "            return SLUM\n",
    "        else:  # if powerstation > 0.07499999925494194\n",
    "            return NON_SLUM\n",
    "    else:  # if residential > 0.13999999687075615\n",
    "        return SLUM\n",
    "    \n",
    "@labeling_function()\n",
    "def lf14(x):\n",
    "    if x.meadows <= 0.03499999921768904:\n",
    "        return NON_SLUM\n",
    "    else:  # if meadows > 0.03499999921768904\n",
    "        return SLUM\n",
    "    \n",
    "@labeling_function()\n",
    "def lf15(x):\n",
    "    if x.glcm_ASM_Scaled <= 0.49999998952262104:\n",
    "        return SLUM\n",
    "    else:  # if glcm_ASM_Scaled > 0.49999998952262104\n",
    "        return NON_SLUM\n",
    "\n",
    "@labeling_function()\n",
    "def lf16(x):\n",
    "    if x.meadows <= 0.20499999821186066:\n",
    "        return SLUM\n",
    "    else:  # if meadows > 0.20499999821186066\n",
    "        if x.roads <= 0.6399999856948853:\n",
    "            if x.glcm_energy_Scaled <= 0.5004999896045774:\n",
    "                return NON_SLUM\n",
    "            else:  # if glcm_energy_Scaled > 0.5004999896045774\n",
    "                return SLUM\n",
    "        else:  # if roads > 0.6399999856948853\n",
    "            return SLUM\n",
    "        \n",
    "@labeling_function()\n",
    "def lf17(x):\n",
    "    if x.glcm_energy_Scaled <= 0.49999999604187906:\n",
    "        return NON_SLUM\n",
    "    else:  # if glcm_energy_Scaled > 0.49999999604187906\n",
    "        return SLUM\n",
    "\n",
    "    \n",
    "@labeling_function()\n",
    "def lf18(x):\n",
    "    if x.shopping_malls <= 0.22500000149011612:\n",
    "        if x.glcm_dissimilarity_Scaled <= 0.8219999969005585:\n",
    "            return SLUM\n",
    "        else:  # if glcm_dissimilarity_Scaled > 0.8219999969005585\n",
    "            return NON_SLUM\n",
    "    else:  # if shopping_malls > 0.22500000149011612\n",
    "        if x.glcm_energy_Scaled <= 0.49999999604187906:\n",
    "            return NON_SLUM\n",
    "        else:  # if glcm_energy_Scaled > 0.49999999604187906\n",
    "            return SLUM\n",
    "        \n",
    "@labeling_function()\n",
    "def lf19(x):\n",
    "    if x.glcm_energy_Scaled <= 0.49999999604187906:\n",
    "        return NON_SLUM\n",
    "    else:  # if glcm_energy_Scaled > 0.49999999604187906\n",
    "        return SLUM\n",
    "\n",
    "@labeling_function()\n",
    "def lf20(x):\n",
    "    if x.glcm_homogeneity_Scaled <= 0.5684999972581863:\n",
    "        return NON_SLUM\n",
    "    else:  # if glcm_homogeneity_Scaled > 0.5684999972581863\n",
    "        if x.healthcare <= 0.574999988079071:\n",
    "            return SLUM\n",
    "        else:  # if healthcare > 0.574999988079071\n",
    "            if x.meadows <= 0.5049999803304672:\n",
    "                return NON_SLUM\n",
    "            else:  # if meadows > 0.5049999803304672\n",
    "                return SLUM\n",
    "            \n",
    "lfs = [\n",
    "    lf1,\n",
    "    lf2,\n",
    "    lf3,\n",
    "    lf4,\n",
    "    lf5,\n",
    "    lf6,\n",
    "    lf7,\n",
    "    lf8,\n",
    "    lf9,\n",
    "    lf10,\n",
    "    lf11,\n",
    "    lf12,\n",
    "    lf13,\n",
    "    lf14,\n",
    "    lf15,\n",
    "    lf16,\n",
    "    lf17,\n",
    "    lf18,\n",
    "    lf19,\n",
    "    lf20\n",
    "]\n",
    "\n",
    "applier = PandasLFApplier(lfs)\n",
    "L_train = applier.apply(y_train)\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "\n",
    "t1 = time.time()\n",
    "label_model.fit(L_train, seed=123, lr=0.01, log_freq=10, n_epochs=300)\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2-t1)\n",
    "# predicted_labels = label_model.predict(L_train)\n",
    "# t2 = time.time()\n",
    "\n",
    "# print(t2-t1)\n",
    "# print(label_model.score(L_train, y_label, metrics=[\"f1_micro\"])['f1_micro'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "21bf2df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 20000/20000 [00:03<00:00, 5600.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38095238095238093 0.5714285714285714\n",
      "0.4571428571428571\n"
     ]
    }
   ],
   "source": [
    "y_train = test.iloc[:,0:18]\n",
    "\n",
    "y_label = test['Class_x']\n",
    "\n",
    "# y_label_new = \n",
    "\n",
    "SLUM = 1\n",
    "NON_SLUM = 0\n",
    "ABSTAIN = -1\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def lf1(x):\n",
    "    if x.glcm_correlation_Scaled <= 0.6509999930858612:\n",
    "        if x.glcm_homogeneity_Scaled <= 0.6689999997615814:\n",
    "            return NON_SLUM\n",
    "        else:  # if glcm_homogeneity_Scaled > 0.6689999997615814\n",
    "            if x.glcm_correlation_Scaled <= 0.4884999990463257:\n",
    "                return NON_SLUM\n",
    "            else:  # if glcm_correlation_Scaled > 0.4884999990463257\n",
    "                return SLUM\n",
    "    else:  # if glcm_correlation_Scaled > 0.6509999930858612\n",
    "        if x.glcm_homogeneity_Scaled <= 0.515500009059906:\n",
    "            return NON_SLUM\n",
    "        else:  # if glcm_homogeneity_Scaled > 0.515500009059906\n",
    "            return SLUM\n",
    "        \n",
    "@labeling_function()\n",
    "def lf2(x):\n",
    "    if x.glcm_energy_Scaled <= 0.5824999958276749:\n",
    "        return NON_SLUM\n",
    "    else:  # if glcm_energy_Scaled > 0.5824999958276749\n",
    "        return SLUM\n",
    "    \n",
    "@labeling_function()\n",
    "def lf3(x):\n",
    "    if x.healthcare <= 0.19999999552965164:\n",
    "        if x.glcm_homogeneity_Scaled <= 0.6480000019073486:\n",
    "            return SLUM\n",
    "        else:  # if glcm_homogeneity_Scaled > 0.6480000019073486\n",
    "            if x.glcm_ASM_Scaled <= 0.49949998955707997:\n",
    "                return NON_SLUM\n",
    "            else:  # if glcm_ASM_Scaled > 0.49949998955707997\n",
    "                return SLUM\n",
    "    else:  # if healthcare > 0.19999999552965164\n",
    "        if x.glcm_homogeneity_Scaled <= 0.8844999969005585:\n",
    "            if x.glcm_contrast_Scaled <= 0.5954999923706055:\n",
    "                return NON_SLUM\n",
    "            else:  # if glcm_contrast_Scaled > 0.5954999923706055\n",
    "                return SLUM\n",
    "        else:  # if glcm_homogeneity_Scaled > 0.88449999690055\n",
    "            return NON_SLUM\n",
    "        \n",
    "@labeling_function()\n",
    "def lf4(x):\n",
    "    if x.glcm_homogeneity_Scaled <= 0.6689999997615814:\n",
    "        return SLUM\n",
    "    else:  # if glcm_homogeneity_Scaled > 0.6689999997615814\n",
    "        if x.glcm_energy_Scaled <= 0.5824999958276749:\n",
    "            return SLUM\n",
    "        else:  # if glcm_energy_Scaled > 0.5824999958276749\n",
    "            return NON_SLUM\n",
    "        \n",
    "\n",
    "@labeling_function()        \n",
    "def lf5(x):\n",
    "    if x.glcm_ASM_Scaled <= 0.6239999830722809:\n",
    "        return SLUM\n",
    "    else:  # if glcm_ASM_Scaled > 0.6239999830722809\n",
    "        return NON_SLUM\n",
    "\n",
    "@labeling_function()\n",
    "def lf6(x):\n",
    "    if x.residential <= 0.4749999940395355:\n",
    "        return NON_SLUM\n",
    "    else:  # if residential > 0.4749999940395355\n",
    "        return SLUM\n",
    "    \n",
    "@labeling_function()\n",
    "def lf7(x):\n",
    "    if x.shopping_malls <= 0.48499999940395355:\n",
    "        return NON_SLUM\n",
    "    else:  # if shopping_malls > 0.48499999940395355\n",
    "        return SLUM\n",
    "    \n",
    "@labeling_function()\n",
    "def lf8(x):\n",
    "    if x.roads <= 0.10999999940395355:\n",
    "        return NON_SLUM\n",
    "    else:  # if roads > 0.10999999940395355\n",
    "        return SLUM  # if leisure > 0.32999999821186066\n",
    "        \n",
    "@labeling_function()\n",
    "def lf9(x):\n",
    "    if x.powerstation <= 0.29500000178813934:\n",
    "        return NON_SLUM\n",
    "    else:  # if powerstation > 0.29500000178813934\n",
    "        return SLUM\n",
    "    \n",
    "@labeling_function()\n",
    "def lf10(x):\n",
    "    if x.shopping_malls <= 0.48499999940395355:\n",
    "        return NON_SLUM\n",
    "    else:  # if shopping_malls > 0.48499999940395355\n",
    "        return SLUM\n",
    "    \n",
    "@labeling_function()    \n",
    "def lf11(x):\n",
    "    if x.residential <= 0.13999999687075615:\n",
    "        if x.glcm_homogeneity_Scaled <= 0.5009999945759773:\n",
    "            return SLUM\n",
    "        else:  # if glcm_homogeneity_Scaled > 0.5009999945759773\n",
    "            return NON_SLUM\n",
    "    else:  # if residential > 0.13999999687075615\n",
    "        return SLUM\n",
    "\n",
    "@labeling_function()\n",
    "def lf12(x):\n",
    "    if x.shopping_malls <= 0.10000000149011612:\n",
    "        if x.glcm_energy_Scaled <= 0.4984999959706329:\n",
    "            return SLUM\n",
    "        else:  # if glcm_energy_Scaled > 0.4984999959706329\n",
    "            return NON_SLUM\n",
    "    else:  # if shopping_malls > 0.10000000149011612\n",
    "        return SLUM\n",
    "    \n",
    "@labeling_function()\n",
    "def lf13(x):\n",
    "    if x.residential <= 0.13999999687075615:\n",
    "        if x.powerstation <= 0.07499999925494194:\n",
    "            return SLUM\n",
    "        else:  # if powerstation > 0.07499999925494194\n",
    "            return NON_SLUM\n",
    "    else:  # if residential > 0.13999999687075615\n",
    "        return SLUM\n",
    "    \n",
    "@labeling_function()\n",
    "def lf14(x):\n",
    "    if x.meadows <= 0.03499999921768904:\n",
    "        return NON_SLUM\n",
    "    else:  # if meadows > 0.03499999921768904\n",
    "        return SLUM\n",
    "    \n",
    "@labeling_function()\n",
    "def lf15(x):\n",
    "    if x.glcm_ASM_Scaled <= 0.49999998952262104:\n",
    "        return SLUM\n",
    "    else:  # if glcm_ASM_Scaled > 0.49999998952262104\n",
    "        return NON_SLUM\n",
    "\n",
    "@labeling_function()\n",
    "def lf16(x):\n",
    "    if x.meadows <= 0.20499999821186066:\n",
    "        return SLUM\n",
    "    else:  # if meadows > 0.20499999821186066\n",
    "        if x.roads <= 0.6399999856948853:\n",
    "            if x.glcm_energy_Scaled <= 0.5004999896045774:\n",
    "                return NON_SLUM\n",
    "            else:  # if glcm_energy_Scaled > 0.5004999896045774\n",
    "                return SLUM\n",
    "        else:  # if roads > 0.6399999856948853\n",
    "            return SLUM\n",
    "        \n",
    "@labeling_function()\n",
    "def lf17(x):\n",
    "    if x.glcm_energy_Scaled <= 0.49999999604187906:\n",
    "        return NON_SLUM\n",
    "    else:  # if glcm_energy_Scaled > 0.49999999604187906\n",
    "        return SLUM\n",
    "\n",
    "    \n",
    "@labeling_function()\n",
    "def lf18(x):\n",
    "    if x.shopping_malls <= 0.22500000149011612:\n",
    "        if x.glcm_dissimilarity_Scaled <= 0.8219999969005585:\n",
    "            return SLUM\n",
    "        else:  # if glcm_dissimilarity_Scaled > 0.8219999969005585\n",
    "            return NON_SLUM\n",
    "    else:  # if shopping_malls > 0.22500000149011612\n",
    "        if x.glcm_energy_Scaled <= 0.49999999604187906:\n",
    "            return NON_SLUM\n",
    "        else:  # if glcm_energy_Scaled > 0.49999999604187906\n",
    "            return SLUM\n",
    "        \n",
    "@labeling_function()\n",
    "def lf19(x):\n",
    "    if x.glcm_energy_Scaled <= 0.49999999604187906:\n",
    "        return NON_SLUM\n",
    "    else:  # if glcm_energy_Scaled > 0.49999999604187906\n",
    "        return SLUM\n",
    "\n",
    "@labeling_function()\n",
    "def lf20(x):\n",
    "    if x.glcm_homogeneity_Scaled <= 0.5684999972581863:\n",
    "        return NON_SLUM\n",
    "    else:  # if glcm_homogeneity_Scaled > 0.5684999972581863\n",
    "        if x.healthcare <= 0.574999988079071:\n",
    "            return SLUM\n",
    "        else:  # if healthcare > 0.574999988079071\n",
    "            if x.meadows <= 0.5049999803304672:\n",
    "                return NON_SLUM\n",
    "            else:  # if meadows > 0.5049999803304672\n",
    "                return SLUM\n",
    "            \n",
    "lfs = [\n",
    "    lf1,\n",
    "    lf2,\n",
    "    lf3,\n",
    "    lf4,\n",
    "    lf5,\n",
    "    lf6,\n",
    "    lf7,\n",
    "    lf8,\n",
    "    lf9,\n",
    "    lf10,\n",
    "    lf11,\n",
    "    lf12,\n",
    "    lf13,\n",
    "    lf14,\n",
    "    lf15,\n",
    "    lf16,\n",
    "    lf17,\n",
    "    lf18,\n",
    "    lf19,\n",
    "    lf20\n",
    "]\n",
    "\n",
    "t1 = time.time()\n",
    "applier = PandasLFApplier(lfs)\n",
    "L_train = applier.apply(y_train)\n",
    "predictions = label_model.predict(L_train)\n",
    "actual = y_label.tolist()\n",
    "predict = predictions.tolist()\n",
    "\n",
    "precision = true_positive(actual, predict)/(true_positive(actual, predict)+false_positive(actual, predict))\n",
    "recall = true_positive(actual, predict)/(true_positive(actual, predict) + false_negative(actual, predict))\n",
    "\n",
    "print(precision, recall)\n",
    "\n",
    "print(2*(precision*recall)/(precision+recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd8b601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
